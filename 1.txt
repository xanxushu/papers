SPEECH EMOTION RECOGNITION WITH DUAL-SEQUENCE LSTM ARCHITECTURE
一、简介
近年来，语音情感识别（SER）作为人机接口技术的重要组成部分受到了广泛关注。 它涉及对语音信号中表达的情绪进行识别和分类。 从语音中准确识别情绪的能力可以增强各种应用，例如人机交互、虚拟助手和基于情绪的治疗系统[1]。

在本次调查中，我们将探讨 SER 的进步，重点是双序列 LSTM (DS-LSTM) 架构、MFCC 特征和梅尔谱图的利用。 这些技术在提高语音信号情绪识别的准确性方面显示出了有希望的结果。 我们还将讨论多模态信息（例如文本和音频）的集成，以增强对语音数据的理解[2][3]。

2. 背景
2.1. 双序列 LSTM 架构
双序列 LSTM (DS-LSTM) 架构是针对 SER 提出的一种新颖方法。 它结合了MFCC特征和梅尔谱图的处理来提高情感分类的准确性。 MFCC 特征捕获语音信号的频谱特征，而梅尔频谱图提供音频信号的时频表示[1]。

DS-LSTM 架构由两个并行的 LSTM 网络组成。 一个 LSTM 处理 MFCC 特征，而另一个 LSTM 处理梅尔谱图。 然后对这些 LSTM 的输出进行平均以产生话语的最终分类。 这种架构允许模型捕获语音信号中存在的频谱和时间信息，从而提高情绪识别性能[1]。

2.2. MFCC特点
梅尔频率倒谱系数 (MFCC) 是语音处理任务（包括 SER）中广泛使用的声学特征。 MFCC 特征是通过应用一系列信号处理技术得出的，例如傅立叶变换、梅尔尺度滤波和对数压缩。 这些特征捕获语音信号的频谱特征，通常用作情感分类机器学习模型的输入[1] [4]。

2.3. 梅尔谱图
梅尔频谱图提供了音频信号随时间变化的频率内容的直观表示。 它们是通过对信号的功率谱应用梅尔尺度滤波而获得的。 梅尔频谱图已广泛用于语音处理任务，包括 SER，因为它们捕获语音信号的频谱和时间信息 [1] [5]。

三、研究进展
3.1. 用于 SER 的双序列 LSTM 架构
双序列 LSTM (DS-LSTM) 架构在提高 SER 准确性方面显示出了可喜的成果。 王等人。 提出了一种 DS-LSTM 模型，该模型可以处理 MFCC 特征和梅尔谱图，以预测语音信号中的情绪。 他们提出的模型的加权精度为 72.7%，未加权精度为 73.3%，优于当前最先进的单峰模型 [1]。

3.2. 多模态语音情感识别
人们已经探索了音频和文本等多模态信息的集成来提高 SER 模型的性能。 尹等人。 提出了一种深度双循环编码器模型，该模型同时利用文本数据和音频信号进行情感识别。 他们的模型使用双循环神经网络 (RNN) 对音频和文本序列中的信息进行编码，并结合这些来源的信息来预测情绪类别。 与仅关注音频特征的模型相比，所提出的架构实现了更高的性能[2]。

何等人。 提出了一种基于多级多头融合注意力机制和循环神经网络（RNN）的语音情感识别多模态方法。 他们的模型从两种模式获取输入：音频和文本。 使用梅尔频率倒谱 (MFCC) 提取音频特征，而使用预训练模型嵌入文本信息。 然后使用自注意力机制处理两种模式的特征，并使用多头注意力技术进行融合。 实验结果表明，两种模式的组合比使用单一模型取得了更好的性能[3]。

3.3. 用于 SER 的深度卷积神经网络
深度卷积神经网络 (DCNN) 已广泛用于 SER 从语音信号中提取高级特征表示。 张等人。 探索使用在 ImageNet 数据集上预训练的 DCNN 模型进行情感分类。 他们采用判别式时间金字塔匹配（DTPM）策略来聚合分段级特征，并在多个公共数据集上取得了可喜的性能[5]。

李等人。 提出了一种混合架构，结合了时间分布式卷积神经网络（TD-CNN）和用于 SER 的长短期记忆（LSTM）网络。 他们的模型处理从音频记录中提取的梅尔频率对数功率谱图（MFLPS）使用滑动窗口方法。 TD-CNN 将输入图像数据转换为一系列高级特征，然后将其馈送到 LSTM 进行整体信号解释。 所提出的架构在广泛使用的 SER 基准数据集上实现了 73.98% 的平均识别准确率 [6]。

3.4. SER 的注意力机制
SER 模型中采用了注意力机制来关注情感相关特征并提高情感识别的性能。 张等人。 提出了一种基于深度卷积神经网络（DCNN）和带注意力的双向长短期记忆（BLSTMwA）的SER模型。 他们模型中的注意力层通过关注情感相关信息来增强语音特征的提取[7]。

哈贾维等人。 引入了语音信号的细粒度早期频率注意（FEFA）模型。 该模型可以专注于特定的频率仓，在频谱图中保留空间信息。 将 FEFA 添加到不同的 CNN 架构中提高了说话人识别和语音情感识别任务的性能 [8]。

4。讨论
使用双序列 LSTM (DS-LSTM) 架构、MFCC 特征和梅尔谱图等技术，语音情绪识别 (SER) 领域已经取得了重大进展。 DS-LSTM 架构通过同时处理 MFCC 特征和梅尔谱图，在提高情绪分类的准确性方面显示出了有希望的结果 [1]。

还探索了音频和文本等多模态信息的集成，以增强对语音数据的理解并提高情感识别性能[2][3]。 这些多模式方法利用不同模式中存在的互补信息来取得更好的结果。

深度卷积神经网络（DCNN）已广泛应用于 SER 中，以从语音信号中提取高级特征表示 [5] [6]。 SER 模型中注意力机制的使用在改善情感相关特征的提取方面也显示出了有希望的结果 [7] [8]。

尽管 SER 取得了进步，但仍然存在需要解决的挑战。 一个限制是缺乏用于训练和评估 SER 模型的大规模注释数据集。 此类数据集的可用性有助于提高 SER 模型的泛化性和鲁棒性 [5]。

另一个挑战是不同文化和语言之间情感表达的差异。 在一种数据集或语言上训练的情绪识别模型可能无法很好地推广到其他数据集或语言。 需要跨文化和跨语言研究来开发更强大和文化敏感的 SER 模型 [9]。

SER在实际场景中的实时应用也是一个挑战。 实时 SER 系统需要高效的算法和架构，能够实时处理语音信号，同时保持高精度 [10]。

5. 结论
语音情绪识别 (SER) 已成为人机接口技术的关键组成部分。 双序列 LSTM (DS-LSTM) 架构、MFCC 特征和梅尔谱图等技术的利用在提高语音信号情感识别的准确性方面显示出了良好的结果。 多模态信息的整合和注意力机制的使用进一步增强了SER模型的性能。

尽管SER取得了进展，但仍然存在一些挑战需要解决，包括大规模注释数据集的可用性、跨文化和跨语言的泛化以及SER在实际场景中的实时应用。 未来的研究应侧重于解决这些挑战，以开发更强大、更高效的 SER 系统。

总体而言，SER 有潜力增强各种应用，包括人机交互、虚拟助手和基于情感的治疗系统，使机器能够理解和响应语音信号中表达的人类情感。

