EMOTION CONTROLLABLE SPEECH SYNTHESIS USING EMOTION-UNLABELED DATASET WITH THE ASSISTANCE OF CROSS-DOMAIN SPEECH EMOTION RECOGNITION

一、简介
语音合成，也称为文本到语音 (TTS) 合成，是将书面文本转换为口语单词的过程。 近年来，由于其广泛的应用，包括虚拟助手、有声读物和针对视障人士的辅助工具，它受到了极大的关注。 另一方面，情绪识别侧重于检测和理解言语中表达的情绪。 通过将语音合成与情绪识别相结合，研究人员已经能够开发出情绪可控的语音合成系统，从而能够生成具有特定情绪表达能力的语音[1]。

神经文本转语音 (TTS) 方法彻底改变了语音合成领域。 这些方法利用深度神经网络直接从文本输入生成高质量的语音波形。 它们在自然度和清晰度方面表现出了卓越的性能，使其成为语音合成领域最先进的方法[2][3]。 然而，传统的神经 TTS 模型需要大量高质量的语音数据进行训练，而这些数据通常很难获得，特别是当涉及到情感标记的数据集时。 这一限制促使研究人员探索在没有情感标签的数据集上进行情感 TTS 合成的替代方法 [1]。

跨域语音情感识别 (SER) 已成为一种有用的技术，可解决获取情感标记数据集以训练情感 TTS 模型的挑战。 通过利用 SER 和 TTS 数据集，研究人员开发了跨域 SER 模型，可以预测 TTS 数据集上的情感标签。 然后，这些预测的情绪标签可用于构建辅助 SER 任务，并与 TTS 模型联合训练。 实验结果表明，该方法可以生成具有指定情感表达力的语音，同时保持语音质量[1]。

在本次调查中，我们将探索语音合成、情感识别、神经文本转语音和跨领域技术的进步。 我们将根据提供的参考文献讨论这些领域的关键概念、研究进展、突破、局限性和未来前景。

2. 背景
2.1. 语音合成
语音合成，也称为文本到语音 (TTS) 合成，是将书面文本转换为口语单词的技术。 几十年来，它一直是一个活跃的研究领域，近年来取得了重大进展。 传统的 TTS 系统依赖于基于规则或串联的合成方法，其中涉及预先录制的语音片段。 然而，这些方法的自然性和表现力往往有限。

神经 TTS 方法的出现彻底改变了语音合成领域。 这些方法利用深度神经网络，例如循环神经网络 (RNN) 和变压器，直接从文本输入生成高质量的语音波形。 神经 TTS 模型在自然度和清晰度方面表现出了卓越的性能，使其成为语音合成领域最先进的方法 [2] [3]。

2.2. 情绪识别
情绪识别旨在检测和理解言语中表达的情绪。 它在人机交互、情感计算和医疗保健等各种应用中发挥着至关重要的作用。 传统的情绪识别方法通常依赖于手工特征和机器学习算法。 然而，这些方法往往难以捕捉情感的复杂性和动态性。

随着深度学习的进步，研究人员转向基于神经网络的情绪识别方法。 这些方法利用深度神经网络，例如卷积神经网络（CNN）和循环神经网络（RNN），自动从语音信号中学习判别特征。 他们在情绪识别性能方面表现出显着的进步，在许多情况下优于传统方法[4]。

2.3. 神经文本转语音
神经文本转语音 (TTS) 是语音合成的一个子领域，专注于使用深度神经网络直接从文本输入生成高质量的语音波形。 神经 TTS 模型在自然度和清晰度方面表现出了卓越的性能，使其成为语音合成领域最先进的方法 [2] [3]。

这些模型通常由编码器-解码器架构组成，其中编码器处理输入文本并生成一系列隐藏表示，解码器从隐藏表示生成相应的语音波形。 编码器和解码器通常基于循环神经网络（RNN）或变压器，它们在序列到序列任务中表现出了出色的性能。

神经 TTS 模型可以使用监督或无监督方法进行训练。 在监督训练中，模型在成对的文本和语音数据上进行训练，其中文本作为输入，相应的语音波形作为目标输出。 在无监督训练中，模型在不配对的文本和语音数据上进行训练，其目标是在没有显式对齐的情况下学习数据中的底层结构和模式。

2.4. 跨域语音情感识别
跨域语音情感识别（SER）是一种旨在识别跨不同域或数据集的语音中表达的情感的技术。 它解决了获取用于训练情感 TTS 模型的情感标记数据集的挑战，该模型通常需要大量带有情感标签的高质量语音数据。

跨域 SER 模型利用 SER 和 TTS 数据集来预测 TTS 数据集上的情感标签。 然后，使用这些预测的情绪标签构建辅助 SER 任务，并与 TTS 模型联合训练。 这种方法允许在没有情感标签的数据集上进行情感 TTS 合成，从而能够生成具有指定情感表达力的语音，同时保持语音质量 [1]。

三、研究进展
3.1. 借助跨域语音情感识别，使用无情感标记数据集进行情感可控语音合成[1]
在本文中，蔡等人。 提出了一种在没有情感标签的 TTS 数据集上进行情感 TTS 合成的新方法。 该方法由跨域语音情感识别（SER）模型和情感 TTS 模型组成。 跨域 SER 模型在 SER 和 TTS 数据集上进行训练，以预测 TTS 数据集上的情感标签。 然后，使用这些预测的情绪标签构建辅助 SER 任务，并与 TTS 模型联合训练。 实验结果表明，该方法可以生成具有指定情感表达力的语音，并且几乎不影响语音质量。

3.2. 基于领域自适应最小二乘回归的跨语料库语音情感识别[5]
宗等人。 提出一种基于领域自适应最小二乘回归（DaLSR）的跨语料库SER方法。 DaLSR方法利用目标语音语料库中额外的未标记数据集作为辅助数据集，并将其与源语音语料库中的标记训练数据集相结合进行联合训练。 DaLSR 的主要新颖之处在于它能够处理源语音语料库和目标语音语料库之间的不匹配问题，使其适合跨语料库 SER。 实验结果表明，所提出的方法在跨语料库 SER 方面优于几种最先进的迁移学习方法。

3.3. 用于端到端语音合成的跨说话者情感解理和转移 [6]
李等人。 提出了一种在跨说话人情感 TTS 任务中合成可控情感表达语音的方法，同时保持目标说话人的身份。 所提出的方法是基于 Tacotron2 的框架，以情感嵌入作为条件变量来提供情感信息。 它包含两个情感解开模块，旨在获得与说话者无关和情感区分的嵌入，并明确地将合成语音的情感和说话者身份限制为预期的那样。 在普通话不相交语料库上的实验结果表明，该方法可以为目标说话人合成合理的情感语音。

3.4. 使用风格标记和半监督训练的端到端情感语音合成[7]
吴等人。 提出一种使用风格标记和半监督训练的端到端情感语音合成方法。 该方法定义风格标记来表示情感类别，并利用标记权重和情感标签之间的交叉熵损失函数来获得风格标记的可解释性。 情感识别实验证实该方法可以有效地实现风格标记和情感类别之间的一一对应。 客观和主观评估结果表明，当只有一小部分训练数据具有情感标签时，该模型优于传统的情感语音合成 Tacotron 模型。

3.5. EMOVIE：具有简单情感文本转语音模型的普通话情感语音数据集 [8]
崔等人。 推出并公开发布普通话情感语音数据集 EMOVIE，其中包含 9,724 个带有音频文件和情感人工标记注释的样本。 他们提出了一种简单但高效的情感语音合成架构，称为 EMSpeech。 与需要额外参考音频作为输入的模型不同，EMSpeech 可以仅根据输入文本预测情感标签，并根据情感嵌入生成更具表现力的语音。 实验结果验证了数据集的有效性，并证明了所提出的模型在情感分类方面的能力。神经 TTS 模型的进步导致了语音合成质量的显着提高，使其成为该领域最先进的方法 [2 ] [3]。 情绪识别也受益于深度学习方法，与传统方法相比实现了更高的准确度[4]。

语音合成和情感识别的结合使得情感可控的语音合成系统得以发展。 跨域 SER 已成为一种有用的技术，可以解决获取情感标记数据集以训练情感 TTS 模型的挑战 [1]。 通过利用 SER 和 TTS 数据集，研究人员能够生成具有特定情感表达能力的语音，同时保持语音质量。

然而，该领域仍然存在一些挑战和限制。 一项主要挑战是缺乏高质量的情感标记语音数据集。 虽然人们已经努力创建情感语音数据集，例如 EMOVIE，但仍然需要更加多样化和全面的数据集 [8]。 另一个挑战是难以控制合成语音中的情绪强度。 虽然一些方法允许控制情绪强度，但仍然需要对情绪强度进行更细粒度的控制[9]。

此外，跨不同领域和语言的情感识别模型的泛化仍然是一个挑战。 跨域和跨语言技术已经被提出来应对这一挑战，但仍有改进的空间[10][11][12]。 此外，情绪可控语音合成模型的可解释性和可解释性是需要考虑的重要因素，因为它们可以帮助用户理解和控制合成语音的情绪表达[13]。

尽管存在这些挑战，该领域的前景还是充满希望的。 深度学习和自然语言处理技术的进步有望进一步提高合成语音的质量和表现力。 更大、更多样化的情感标记语音数据集的可用性也将有助于开发更强大、更准确的情感识别模型。 此外，多模态信息（例如面部表情和手势）与语音合成和情感识别的集成可以带来更真实和身临其境的人机交互[14][15]。

5. 结论
总之，语音合成、情感识别、神经文本转语音和跨领域技术近年来取得了重大进展。 神经 TTS 模型彻底改变了语音合成，在自然度和清晰度方面取得了卓越的性能。 情绪识别也受益于深度学习方法，能够更准确地检测和理解语音中表达的情绪。

语音合成和情感识别的结合促进了情感可控语音合成系统的发展。 跨域 SER 技术解决了获取情感标记数据集以训练情感 TTS 模型的挑战，从而可以生成具有指定情感表达能力的语音。

然而，该领域仍然存在挑战和局限性，包括高质量情感标记语音数据集的稀缺、合成语音中情感强度的难以控制以及跨不同领域和语言的情感识别模型的泛化。 尽管存在这些挑战，但随着深度学习和自然语言处理技术的进步、更大、更多样化的情感标记语音数据集的可用性以及多模态信息的集成，该领域的前景还是充满希望的。

这些领域的进一步研究和开发将有助于改善情绪可控的语音合成系统，实现更真实、更具表现力的人机交互。
